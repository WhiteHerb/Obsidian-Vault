
> 1. #감정_분류
> 2. #나이브_베이즈
> 3. #나이브_베이즈_기반_감정_분류
> 4. #scikit-learn_라이브러리를_이용한_시스템_구축

---
# 1. #감정_분류
### 데이터의 종류

본격적인 이야기에 앞서 이곳에선 텍스트 데이터를 크게 객관적인 글과 주관적 글로 나누고자 한다

- 객관적 글:
	뉴스나 사전 같은 경우로 정보 전달 등의 목적을 지닌 글

- 주관적 글:
	리뷰와 같이 주관이나 감상이 들어간 글

오늘의 목표는 주관적인 글에 포함된 감정을 구분해내는 것이다

## 감정 분류란
문장의 구성 및 언어적 특징을 기반으로 각 문장을 특정 감정에 분류하는 것이다.

| 문장 | 감정 |
| ----- | ----- |
| 이 캐릭터가 죽은게 아쉽네요.. | 슬픔 |
| 와 이 명작을 다시보다니.. | 기쁨 |

이처럼 문장에 특정 감정이 담기는 경우 특정 단어나 구조가 반복되므로 이를 기반으로 감정 분류 시스템을 만들고자 한다

---
# 2. #나이브_베이즈 

나이브 베이즈란
> 주어진 특정 텍스트가 어떠한 범주에 포함될 확률을 말한다

이를 수식으로 나타내게 되면 다음과 같다.
> _P(S|T)_ 
 
이러한 나이브 베이츠에서 대상을 분류하는데 사용하는 특징들은 _전부 독립적_ 이며(이번에는 문장을 구성하는 각각의 단어들로 생각할 수 있다) 문제와 답이 주어지는 **지도 학습** 에서 효율적으로 사용될 수 있다

----
# 3. #나이브_베이즈_기반_감정_분류 

다시 한번 수식을 보자. 이번엔 수식의 각각의 변수를 아래와 같이 표현할 수 있다
> P(S|T) 
> 
> S: 감정
> T: 텍스트
> 
> 즉 P(감정 | 텍스트) 이다

이를 풀어보면
> P(감정 | 텍스트) = P(감정) * P(텍스트 | 감정) / P(텍스트)

이고 이를 해석해보면 아래와 같다

>나타날 확률 = 나타난 빈도 라는 가정에서
>
>P(감정): 전체 데이터셋중 이 감정이 나타날 확률
>P(텍스트): 전체 데이터셋중 이 텍스트가 나타날 확률
>P(텍스트 | 감정): 특정 감정으로 분류된 텍스트들 중에서 이 텍스트가 나타날 확률

이제 한번 실제로 해보자

---
# 4. #scikit-learn_라이브러리를_이용한_시스템_구축 

scikit-learn라이브러리는 내부적으로 나이브 베이즈 모델을 제공한다

